---
# Source: cephobjectstore/templates/rbac/label-storage-bundle-sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: label-storage-nodes
  namespace: openshift-storage
  annotations:
    argocd.argoproj.io/sync-wave: "1"
---
# Source: cephobjectstore/templates/rbac/label-storage-bundle-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "1"
  name: label-storage-nodes
rules:
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - get
      - list
      - patch
      - update
---
# Source: cephobjectstore/templates/rbac/label-storage-bundle-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: label-storage-nodes
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: label-storage-nodes
subjects:
  - kind: ServiceAccount
    name: label-storage-nodes
    namespace: openshift-storage
---
# Source: cephobjectstore/templates/rbac/quay-noobaa-deploy-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: quay-noobaa-deploy-role
  annotations:
    argocd.argoproj.io/sync-wave: "2"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: quay-admin-role
subjects:
  - kind: ServiceAccount
    name: quay-admin-sa
    namespace: openshift-storage
---
# Source: cephobjectstore/templates/label-storage-nodes-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/sync-wave: "3"
  name: label-storage-nodes-bundle
spec:
  template:
    spec:
      containers:
        - image: image-registry.openshift-image-registry.svc:5000/openshift/cli:latest
          command:
            - /bin/bash
            - -c
            - |
              #!/usr/bin/env bash
              set -e
              if ! oc get nodes -l cluster.ocs.openshift.io/openshift-storage= ; then
                 echo "Worker nodes already labeled for storage"
                exit 0
              else
                # Wait for central to be ready
                attempt_counter=0
                max_attempts=20
                echo "Labeling all worker nodes for storage"
                oc label node -l node-role.kubernetes.io/worker= cluster.ocs.openshift.io/openshift-storage=
                echo "Worker nodes labeled for storage"
              fi
          imagePullPolicy: Always
          name: label-storage-nodes-bundle
      dnsPolicy: ClusterFirst
      restartPolicy: Never
      serviceAccount: label-storage-nodes
      serviceAccountName: label-storage-nodes
      terminationGracePeriodSeconds: 30
---
# Source: cephobjectstore/templates/storagecluster.yaml
apiVersion: ocs.openshift.io/v1
kind: StorageCluster
metadata:
  annotations:
    uninstall.ocs.openshift.io/cleanup-policy: delete
    uninstall.ocs.openshift.io/mode: graceful
  finalizers:
  - storagecluster.ocs.openshift.io
  name: ocs-storagecluster
  namespace: openshift-storage
spec:
  arbiter: {}
  encryption:
    kms: {}
  externalStorage: {}
  managedResources:
    cephBlockPools: {}
    cephCluster: {}
    cephConfig: {}
    cephDashboard: {}
    cephFilesystems: {}
    cephObjectStoreUsers: {}
    cephObjectStores: {}
  mirroring: {}
  multiCloudGateway:
    dbStorageClassName: gp2
    reconcileStrategy: standalone
